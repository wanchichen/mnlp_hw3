<!DOCTYPE html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.51" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="https://lileicc.github.io/blog/mt/mnlp_blog/"><meta property="og:site_name" content="MLNLP Blog"><meta property="og:title" content="Multilingual Machine Translation with Large Language Models"><meta property="og:type" content="article"><meta property="og:updated_time" content="2023-11-17T03:07:56.000Z"><meta property="og:locale" content="en-US"><meta property="article:author" content="Hwijeen Ahn, William Chen"><meta property="article:tag" content="Multilingual MT"><meta property="article:published_time" content="2023-11-16T00:00:00.000Z"><meta property="article:modified_time" content="2023-11-17T03:07:56.000Z"><title>Multilingual Machine Translation with Large Language Models | MLNLP Blog</title><meta name="description" content="A Blog for Machine Learning, Natural Language Processing, and Data Mining">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d2025;
      }

      html,
      body {
        background-color: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.querySelector("html").setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="stylesheet" href="/blog/assets/style.758fbe27.css">
    <link rel="modulepreload" href="/blog/assets/app.594b312f.js"><link rel="modulepreload" href="/blog/assets/index.html.9bb35b1e.js"><link rel="modulepreload" href="/blog/assets/_plugin-vue_export-helper.cdc0426e.js"><link rel="modulepreload" href="/blog/assets/index.html.5229cee4.js"><link rel="prefetch" href="/blog/assets/index.html.48d72793.js"><link rel="prefetch" href="/blog/assets/index.html.a49e14cc.js"><link rel="prefetch" href="/blog/assets/index.html.84f09450.js"><link rel="prefetch" href="/blog/assets/index.html.948f6ba7.js"><link rel="prefetch" href="/blog/assets/index.html.4e8ce27b.js"><link rel="prefetch" href="/blog/assets/index.html.cc204d40.js"><link rel="prefetch" href="/blog/assets/index.html.9d3d23de.js"><link rel="prefetch" href="/blog/assets/index.html.e207b34f.js"><link rel="prefetch" href="/blog/assets/index.html.6fe109c4.js"><link rel="prefetch" href="/blog/assets/index.html.f2001ec9.js"><link rel="prefetch" href="/blog/assets/index.html.f13e23f3.js"><link rel="prefetch" href="/blog/assets/index.html.36a209ea.js"><link rel="prefetch" href="/blog/assets/index.html.e51071bb.js"><link rel="prefetch" href="/blog/assets/index.html.3b54c059.js"><link rel="prefetch" href="/blog/assets/index.html.9bc33622.js"><link rel="prefetch" href="/blog/assets/index.html.1b2f4c5b.js"><link rel="prefetch" href="/blog/assets/index.html.2693264c.js"><link rel="prefetch" href="/blog/assets/index.html.371141f3.js"><link rel="prefetch" href="/blog/assets/index.html.e3b8fd71.js"><link rel="prefetch" href="/blog/assets/index.html.3cc17b99.js"><link rel="prefetch" href="/blog/assets/index.html.d6d3e578.js"><link rel="prefetch" href="/blog/assets/index.html.9a21b56f.js"><link rel="prefetch" href="/blog/assets/index.html.1f3a298a.js"><link rel="prefetch" href="/blog/assets/404.html.144ea56c.js"><link rel="prefetch" href="/blog/assets/index.html.3a32b4c3.js"><link rel="prefetch" href="/blog/assets/index.html.3eaba85c.js"><link rel="prefetch" href="/blog/assets/index.html.9c8e527a.js"><link rel="prefetch" href="/blog/assets/index.html.949c6932.js"><link rel="prefetch" href="/blog/assets/index.html.9369be8b.js"><link rel="prefetch" href="/blog/assets/index.html.5ecb22f0.js"><link rel="prefetch" href="/blog/assets/index.html.0a31196e.js"><link rel="prefetch" href="/blog/assets/index.html.1b68751c.js"><link rel="prefetch" href="/blog/assets/index.html.85fce0bc.js"><link rel="prefetch" href="/blog/assets/index.html.7d865fc8.js"><link rel="prefetch" href="/blog/assets/index.html.73acbfb4.js"><link rel="prefetch" href="/blog/assets/index.html.7e45f7bf.js"><link rel="prefetch" href="/blog/assets/index.html.620dcedf.js"><link rel="prefetch" href="/blog/assets/index.html.83d0711e.js"><link rel="prefetch" href="/blog/assets/index.html.b4a0aa08.js"><link rel="prefetch" href="/blog/assets/index.html.7adb01cb.js"><link rel="prefetch" href="/blog/assets/index.html.f005e561.js"><link rel="prefetch" href="/blog/assets/index.html.7fb0dc28.js"><link rel="prefetch" href="/blog/assets/index.html.71f8befa.js"><link rel="prefetch" href="/blog/assets/index.html.92c68d7e.js"><link rel="prefetch" href="/blog/assets/index.html.055d7455.js"><link rel="prefetch" href="/blog/assets/index.html.df6f3f04.js"><link rel="prefetch" href="/blog/assets/index.html.00dbedea.js"><link rel="prefetch" href="/blog/assets/index.html.603bf394.js"><link rel="prefetch" href="/blog/assets/index.html.cd4b9e10.js"><link rel="prefetch" href="/blog/assets/index.html.be0f419f.js"><link rel="prefetch" href="/blog/assets/index.html.bc51d0ae.js"><link rel="prefetch" href="/blog/assets/index.html.b79794f0.js"><link rel="prefetch" href="/blog/assets/index.html.eb8e4cee.js"><link rel="prefetch" href="/blog/assets/index.html.5c842c2c.js"><link rel="prefetch" href="/blog/assets/index.html.a95edb3c.js"><link rel="prefetch" href="/blog/assets/index.html.13db0b56.js"><link rel="prefetch" href="/blog/assets/index.html.bad01ddf.js"><link rel="prefetch" href="/blog/assets/index.html.ed77c4d1.js"><link rel="prefetch" href="/blog/assets/index.html.a3514a8d.js"><link rel="prefetch" href="/blog/assets/index.html.65bca0e5.js"><link rel="prefetch" href="/blog/assets/index.html.5bb552c5.js"><link rel="prefetch" href="/blog/assets/index.html.6eb9e54e.js"><link rel="prefetch" href="/blog/assets/index.html.62d61c88.js"><link rel="prefetch" href="/blog/assets/index.html.1362a299.js"><link rel="prefetch" href="/blog/assets/index.html.68f9bc07.js"><link rel="prefetch" href="/blog/assets/index.html.0272cd41.js"><link rel="prefetch" href="/blog/assets/index.html.3b47eb32.js"><link rel="prefetch" href="/blog/assets/index.html.d8dad1e7.js"><link rel="prefetch" href="/blog/assets/index.html.f01de255.js"><link rel="prefetch" href="/blog/assets/index.html.415c7585.js"><link rel="prefetch" href="/blog/assets/index.html.c876a430.js"><link rel="prefetch" href="/blog/assets/index.html.1b3b1bb2.js"><link rel="prefetch" href="/blog/assets/index.html.d1ba8a2a.js"><link rel="prefetch" href="/blog/assets/index.html.ba6b6066.js"><link rel="prefetch" href="/blog/assets/index.html.59861a75.js"><link rel="prefetch" href="/blog/assets/index.html.d111e66d.js"><link rel="prefetch" href="/blog/assets/index.html.1360baea.js"><link rel="prefetch" href="/blog/assets/index.html.037552ca.js"><link rel="prefetch" href="/blog/assets/index.html.4d379833.js"><link rel="prefetch" href="/blog/assets/index.html.f3bbc1a7.js"><link rel="prefetch" href="/blog/assets/index.html.9a55a009.js"><link rel="prefetch" href="/blog/assets/index.html.3bc405f4.js"><link rel="prefetch" href="/blog/assets/index.html.2960f0f3.js"><link rel="prefetch" href="/blog/assets/index.html.2372a3ca.js"><link rel="prefetch" href="/blog/assets/index.html.5ede9284.js"><link rel="prefetch" href="/blog/assets/index.html.d1330d5e.js"><link rel="prefetch" href="/blog/assets/index.html.392406ae.js"><link rel="prefetch" href="/blog/assets/index.html.42e342a2.js"><link rel="prefetch" href="/blog/assets/index.html.d6f5332b.js"><link rel="prefetch" href="/blog/assets/index.html.ba19f087.js"><link rel="prefetch" href="/blog/assets/index.html.57ec46f4.js"><link rel="prefetch" href="/blog/assets/index.html.66f57ee8.js"><link rel="prefetch" href="/blog/assets/index.html.b931f1d2.js"><link rel="prefetch" href="/blog/assets/index.html.3b6fc40f.js"><link rel="prefetch" href="/blog/assets/index.html.0a2465ca.js"><link rel="prefetch" href="/blog/assets/index.html.ae2d984c.js"><link rel="prefetch" href="/blog/assets/index.html.60726688.js"><link rel="prefetch" href="/blog/assets/index.html.ab8e56be.js"><link rel="prefetch" href="/blog/assets/404.html.8ca2bc4d.js"><link rel="prefetch" href="/blog/assets/index.html.4731b2c2.js"><link rel="prefetch" href="/blog/assets/index.html.9b0b5e21.js"><link rel="prefetch" href="/blog/assets/index.html.3c48e5b2.js"><link rel="prefetch" href="/blog/assets/index.html.1cbfec95.js"><link rel="prefetch" href="/blog/assets/index.html.3e137e67.js"><link rel="prefetch" href="/blog/assets/index.html.8ab7607e.js"><link rel="prefetch" href="/blog/assets/index.html.4a45580d.js"><link rel="prefetch" href="/blog/assets/index.html.8a42abff.js"><link rel="prefetch" href="/blog/assets/index.html.fd7adad1.js"><link rel="prefetch" href="/blog/assets/index.html.90efb0a2.js"><link rel="prefetch" href="/blog/assets/index.html.8340a103.js"><link rel="prefetch" href="/blog/assets/index.html.f2c8a989.js"><link rel="prefetch" href="/blog/assets/index.html.6ffa4554.js"><link rel="prefetch" href="/blog/assets/index.html.040e0820.js"><link rel="prefetch" href="/blog/assets/index.html.a870858a.js"><link rel="prefetch" href="/blog/assets/index.html.e870eb6a.js"><link rel="prefetch" href="/blog/assets/index.html.b1d921c0.js"><link rel="prefetch" href="/blog/assets/index.html.299c1956.js"><link rel="prefetch" href="/blog/assets/index.html.9e654515.js"><link rel="prefetch" href="/blog/assets/index.html.0200c99a.js"><link rel="prefetch" href="/blog/assets/index.html.d078eac6.js"><link rel="prefetch" href="/blog/assets/index.html.11be68cf.js"><link rel="prefetch" href="/blog/assets/index.html.2cbff63b.js"><link rel="prefetch" href="/blog/assets/index.html.2e152dd2.js"><link rel="prefetch" href="/blog/assets/index.html.81968f64.js"><link rel="prefetch" href="/blog/assets/index.html.060b56a2.js"><link rel="prefetch" href="/blog/assets/index.html.bef1894a.js"><link rel="prefetch" href="/blog/assets/index.html.c53ae529.js"><link rel="prefetch" href="/blog/assets/index.html.ee684716.js"><link rel="prefetch" href="/blog/assets/index.html.af42326d.js"><link rel="prefetch" href="/blog/assets/index.html.b6d7ea4c.js"><link rel="prefetch" href="/blog/assets/index.html.e1439a6d.js"><link rel="prefetch" href="/blog/assets/index.html.7dfd3eec.js"><link rel="prefetch" href="/blog/assets/index.html.d0a3069b.js"><link rel="prefetch" href="/blog/assets/index.html.7a502b95.js"><link rel="prefetch" href="/blog/assets/index.html.6d9c534f.js"><link rel="prefetch" href="/blog/assets/index.html.6cdfc024.js"><link rel="prefetch" href="/blog/assets/index.html.deb6a58d.js"><link rel="prefetch" href="/blog/assets/index.html.7a0d8de9.js"><link rel="prefetch" href="/blog/assets/index.html.9a1c68eb.js"><link rel="prefetch" href="/blog/assets/index.html.c33633b6.js"><link rel="prefetch" href="/blog/assets/index.html.3cde8f9a.js"><link rel="prefetch" href="/blog/assets/index.html.8a2f4a4c.js"><link rel="prefetch" href="/blog/assets/index.html.5f099f99.js"><link rel="prefetch" href="/blog/assets/index.html.61bc2058.js"><link rel="prefetch" href="/blog/assets/index.html.c939caff.js"><link rel="prefetch" href="/blog/assets/index.html.e98c3bda.js"><link rel="prefetch" href="/blog/assets/index.html.0f81c3f9.js"><link rel="prefetch" href="/blog/assets/index.html.5157ca1f.js"><link rel="prefetch" href="/blog/assets/index.html.9547a1c7.js"><link rel="prefetch" href="/blog/assets/index.html.446e96a7.js"><link rel="prefetch" href="/blog/assets/giscus.15440425.js"><link rel="prefetch" href="/blog/assets/highlight.esm.d982e650.js"><link rel="prefetch" href="/blog/assets/markdown.esm.832a189d.js"><link rel="prefetch" href="/blog/assets/math.esm.a3f84b6f.js"><link rel="prefetch" href="/blog/assets/notes.esm.3c361cb7.js"><link rel="prefetch" href="/blog/assets/reveal.esm.b96f05d8.js"><link rel="prefetch" href="/blog/assets/search.esm.80da4a02.js"><link rel="prefetch" href="/blog/assets/zoom.esm.8514a202.js"><link rel="prefetch" href="/blog/assets/photoswipe.esm.382b1873.js">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="skip-link sr-only">Skip to content</a><!--]--><div class="theme-container no-sidebar has-toc"><!--[--><!--[--><header class="navbar"><div class="navbar-left"><button class="toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><a href="/blog/" class="brand"><img class="logo" src="/blog/logo.svg" alt="MLNLP Blog"><!----><span class="site-name hide-in-pad">MLNLP Blog</span></a><!----></div><div class="navbar-center"><!----><nav class="nav-links"><div class="nav-item hide-in-mobile"><a href="/blog/" class="nav-link" aria-label="Blog Home"><span class="icon iconfont icon-home"></span>Blog Home<!----></a></div><div class="nav-item hide-in-mobile"><a href="/blog/category/" class="nav-link" aria-label="Category"><span class="icon iconfont icon-categoryselected"></span>Category<!----></a></div><div class="nav-item hide-in-mobile"><a href="/blog/tag/" class="nav-link" aria-label="Tags"><span class="icon iconfont icon-tag"></span>Tags<!----></a></div><div class="nav-item hide-in-mobile"><a href="/blog/timeline/" class="nav-link" aria-label="Timeline"><span class="icon iconfont icon-time"></span>Timeline<!----></a></div></nav><!----></div><div class="navbar-right"><!----><!----><div class="nav-item"><a class="repo-link" href="https://github.com/lileicc/blog" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form><!----><button class="toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span class="button-container"><span class="button-top"></span><span class="button-middle"></span><span class="button-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow left"></span></div><aside class="sidebar"><!--[--><!----><!--]--><ul class="sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main class="page" id="main-content"><!--[--><!----><nav class="breadcrumb disable"></nav><div class="page-title"><h1><!---->Multilingual Machine Translation with Large Language Models</h1><div class="page-info"><span class="author-info" aria-label="Author🖊" data-balloon-pos="down" localizeddate="November 16, 2023" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="author-item">Hwijeen Ahn, William Chen</span></span><span property="author" content="Hwijeen Ahn, William Chen"></span></span><!----><span class="date-info" aria-label="Writing Date📅" data-balloon-pos="down" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span>November 16, 2023</span><meta property="datePublished" content="2023-11-16T00:00:00.000Z"></span><span class="category-info" aria-label="Category🌈" data-balloon-pos="down" localizeddate="November 16, 2023" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><ul class="categories-wrapper"><li class="category category4 clickable" role="navigation">MT</li><meta property="articleSection" content="MT"></ul></span><span aria-label="Tag🏷" data-balloon-pos="down" localizeddate="November 16, 2023" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><ul class="tags-wrapper"><li class="tag tag7 clickable" role="navigation">Multilingual MT</li></ul><meta property="keywords" content="Multilingual MT"></span><span class="reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down" localizeddate="November 16, 2023" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 3 min</span><meta property="timeRequired" content="PT3M"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><div class="toc-header">On This Page</div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/blog/mt/mnlp_blog/#introduction" class="router-link-active router-link-exact-active toc-link level2">Introduction</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/blog/mt/mnlp_blog/#in-context-learning" class="router-link-active router-link-exact-active toc-link level2">In-Context Learning</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/blog/mt/mnlp_blog/#llms-vs-dedicated-mt-models" class="router-link-active router-link-exact-active toc-link level2">LLMs vs Dedicated MT Models</a></li><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/blog/mt/mnlp_blog/#evaluated-models" class="router-link-active router-link-exact-active toc-link level3">Evaluated Models</a></li><!----><!--]--></ul><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/blog/mt/mnlp_blog/#factors-that-influence-an-llm-s-translation-performance" class="router-link-active router-link-exact-active toc-link level2">Factors that Influence an LLM&#39;s Translation Performance</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/blog/mt/mnlp_blog/#how-to-use-in-context-learning-on-your-own-data" class="router-link-active router-link-exact-active toc-link level2">How to use In-Context Learning on your own Data</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/blog/mt/mnlp_blog/#conclusion" class="router-link-active router-link-exact-active toc-link level2">Conclusion</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/blog/mt/mnlp_blog/#references" class="router-link-active router-link-exact-active toc-link level2">References</a></li><!----><!--]--></ul></div></aside></div><!----><div class="theme-hope-content"><p>Large Language Models (LLMs) like <a href="chat.openai.com">ChatGPT</a> have rocked the world over the past year. They are able to perform almost any task you can think of, such as summarization, translation, and story-telling. But how do these LLMs work? And should you use them over existing tools? A <a href="https://arxiv.org/pdf/2304.04675.pdf" target="_blank" rel="noopener noreferrer">recent study<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> by AI researchers investigated how LLMs can be used for translation, and evaluate them against the best dedicated translation systems available. Our blog post today will summarize their findings and show how their study can be extended to new languages.</p><!-- more --><p>Paper: <a href="https://arxiv.org/abs/2304.04675" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2304.04675<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>Code: <a href="https://github.com/NJUNLP/MMT-LLM" target="_blank" rel="noopener noreferrer">https://github.com/NJUNLP/MMT-LLM<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction" aria-hidden="true">#</a> Introduction</h2><h2 id="in-context-learning" tabindex="-1"><a class="header-anchor" href="#in-context-learning" aria-hidden="true">#</a> In-Context Learning</h2><p>Large-scale machine learning models are trained on an extremely vast amount of data. But when it comes down to actual usage, we typically only need these models to perform certain tasks in certain domains. Thus, it is common to take a model pre-trained on a large general dataset and fine-tune it on a smaller task/domain specific dataset. However, this process is still expensive, as the amount of data necessary to achieve good performance on specific tasks after fine-tuning is still rather large, and the fine-tuning process itself requires access to GPU compute. Can we instead teach a model to perform a task without fine-tuning?</p><p>Recent research has shown that we can do achieve this with, in-context learning (ICL): the concept of showing an LLM a few examples of a task, before asking it to complete the task for a new data. In the context of translation, for example, this can be done by giving the LLM a few example translations, such as:</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>I love potatoes -&gt; J&#39;aime les pommes de terre
Where did you buy that purse? -&gt; Où as-tu acheté ce sac à main?
You can feed deer at Nara Park -&gt; Vous pouvez nourrir les cerfs au parc de Nara
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Before asking it giving it this task:</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>Let’s see if its value is mentioned in any other responses. -&gt;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>As you can probably guess, the examples you give the LLM can significantly affect its ability to perform ICL. The examples need to be represent the different possible ways to properly perform the task. As such, you may need to perform significant amounts of engineering to properly teach the LLM more difficult tasks, such as translation with rare languages or uncommon language pairs. ICL is possible in LLMs due to the nature of their pre-training task: predicting the next word. The examples provided by the user for ICL becomes the context the LLM uses to reatedly predict the next word, evenutally forming an output translation. This makes ICL a property mostly unique to LLMs, as it requires a specific pre-training type, along with a sufficiently large model/dataset.</p><h2 id="llms-vs-dedicated-mt-models" tabindex="-1"><a class="header-anchor" href="#llms-vs-dedicated-mt-models" aria-hidden="true">#</a> LLMs vs Dedicated MT Models</h2><h3 id="evaluated-models" tabindex="-1"><a class="header-anchor" href="#evaluated-models" aria-hidden="true">#</a> Evaluated Models</h3><p>The study compared eight LLMs (XGLM-7.5B, OPT-175B, Falcon-7B, BLOOMZ-7.1B, LLAMA2-7B, LLAMA2-7B-chat, ChatGPT, and GPT-4) with three dedicated multilingual machine translation (MT)models (M2M-100-12B, NLLB-1.3B, and Google Translate). A comparison is shown in the following table:</p><table><thead><tr><th style="text-align:center;">Model</th><th style="text-align:center;">Type</th><th style="text-align:center;">Parameters</th><th style="text-align:center;">Notes</th></tr></thead><tbody><tr><td style="text-align:center;">XGLM</td><td style="text-align:center;">LLM</td><td style="text-align:center;">7.5B</td><td style="text-align:center;">Multilingual</td></tr><tr><td style="text-align:center;">OPT</td><td style="text-align:center;">LLM</td><td style="text-align:center;">175B</td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;">Falcon</td><td style="text-align:center;">LLM</td><td style="text-align:center;">7B</td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;">BLOOMZ</td><td style="text-align:center;">LLM</td><td style="text-align:center;">7.1B</td><td style="text-align:center;">Multilingual</td></tr><tr><td style="text-align:center;">LLaMA2</td><td style="text-align:center;">LLM</td><td style="text-align:center;">7B</td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;">LLaMA2-chat</td><td style="text-align:center;">LLM</td><td style="text-align:center;">7B</td><td style="text-align:center;">Trained for chatting</td></tr><tr><td style="text-align:center;">ChatGPT</td><td style="text-align:center;">LLM</td><td style="text-align:center;">175B</td><td style="text-align:center;">Trained for chatting</td></tr><tr><td style="text-align:center;">GPT-4</td><td style="text-align:center;">LLM</td><td style="text-align:center;">Unknown</td><td style="text-align:center;">Commercial product, multimodal, trained for chatting</td></tr><tr><td style="text-align:center;">M2M-100</td><td style="text-align:center;">MT</td><td style="text-align:center;">12B</td><td style="text-align:center;">Trained on 100 languages</td></tr><tr><td style="text-align:center;">NLLB</td><td style="text-align:center;">MT</td><td style="text-align:center;">1.3B</td><td style="text-align:center;">Trained on 200 languages</td></tr><tr><td style="text-align:center;">Google Translate</td><td style="text-align:center;">MT</td><td style="text-align:center;">Unknown</td><td style="text-align:center;">Commercial product</td></tr></tbody></table><p>We categorize each model by their type and also include their number of parameters, which represenmts the size of the model. Having more parameters allows the model to store more information. You can think of it like the size of the AI&#39;s brain: a bigger brain is smarter than a smaller one, but more expensive to maintain. You&#39;ll also notice that some LLMs are denoted as multilingual, meaning their creators chose to specifically give them more training data from languages other than English. That doesn&#39;t mean the other LLMs aren&#39;t trained on other languages, they just see much less of it and aren&#39;t optimized for handling more languages [1].</p><h2 id="factors-that-influence-an-llm-s-translation-performance" tabindex="-1"><a class="header-anchor" href="#factors-that-influence-an-llm-s-translation-performance" aria-hidden="true">#</a> Factors that Influence an LLM&#39;s Translation Performance</h2><ol><li>LLMs can acquire translation ability in a resource-efficient way.</li><li>Good performance requires a carefully-designed template</li></ol><h2 id="how-to-use-in-context-learning-on-your-own-data" tabindex="-1"><a class="header-anchor" href="#how-to-use-in-context-learning-on-your-own-data" aria-hidden="true">#</a> How to use In-Context Learning on your own Data</h2><h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="#conclusion" aria-hidden="true">#</a> Conclusion</h2><h2 id="references" tabindex="-1"><a class="header-anchor" href="#references" aria-hidden="true">#</a> References</h2><p>[1] Briakou, Eleftheria, Colin Cherry, and George Foster. &quot;Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM&#39;s Translation Capability.&quot; arXiv preprint arXiv:2305.10266 (2023).</p></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/lileicc/blog/edit/main/mt/mnlp_blog/README.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item update-time"><span class="label">Last update: </span><span class="info">11/17/2023, 3:07:56 AM</span></div><div class="meta-item contributors"><span class="label">Contributors: </span><!--[--><!--[--><span class="contributor" title="email: wchen6255@outlook.com">wanchichen</span><!--]--><!--]--></div></footer><!----><div class="giscus-wrapper input-top" style="display:block;"><div style="text-align:center">Loading...</div></div><!----><!--]--></main><!--]--><footer class="footer-wrapper"><div class="footer">Li Lab</div><div class="copyright">Copyright © 2023 Hwijeen Ahn, William Chen</div></footer><!--]--></div><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app.594b312f.js" defer></script>
  </body>
</html>
