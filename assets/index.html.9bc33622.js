const e=JSON.parse('{"key":"v-6c37a1e9","path":"/dl4mt/2021/lightseq/","title":"Accelerating the Computation on GPUs for Natural Language Processing","lang":"en-US","frontmatter":{"title":"Accelerating the Computation on GPUs for Natural Language Processing","author":"Bowen Zhang","date":"2021-12-10T00:00:00.000Z","tag":["Transformer","GPU Acceleration","CUDA"],"category":["NLP","DL4MT"],"summary":"A high performance open-source library for NLP Transformer model training and inferencing.\\n","head":[["meta",{"property":"og:url","content":"https://lileicc.github.io/blog/dl4mt/2021/lightseq/"}],["meta",{"property":"og:site_name","content":"MLNLP Blog"}],["meta",{"property":"og:title","content":"Accelerating the Computation on GPUs for Natural Language Processing"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://lileicc.github.io/blog/"}],["meta",{"property":"og:updated_time","content":"2022-09-13T03:45:15.000Z"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"Accelerating the Computation on GPUs for Natural Language Processing"}],["meta",{"property":"article:author","content":"Bowen Zhang"}],["meta",{"property":"article:tag","content":"Transformer"}],["meta",{"property":"article:tag","content":"GPU Acceleration"}],["meta",{"property":"article:tag","content":"CUDA"}],["meta",{"property":"article:published_time","content":"2021-12-10T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2022-09-13T03:45:15.000Z"}]]},"excerpt":"<p>A high performance open-source library for NLP Transformer model training and inferencing.</p>\\n","headers":[{"level":2,"title":"1. What is LightSeq?","slug":"_1-what-is-lightseq","link":"#_1-what-is-lightseq","children":[{"level":3,"title":"1.1 NLP models","slug":"_1-1-nlp-models","link":"#_1-1-nlp-models","children":[]},{"level":3,"title":"1.2 Motivation","slug":"_1-2-motivation","link":"#_1-2-motivation","children":[]},{"level":3,"title":"1.3 Lightseq","slug":"_1-3-lightseq","link":"#_1-3-lightseq","children":[]}]},{"level":2,"title":"2. Technique Details","slug":"_2-technique-details","link":"#_2-technique-details","children":[{"level":3,"title":"2.1 Operation Fusion","slug":"_2-1-operation-fusion","link":"#_2-1-operation-fusion","children":[]},{"level":3,"title":"2.2 Hierarchical Auto-Regressive Search","slug":"_2-2-hierarchical-auto-regressive-search","link":"#_2-2-hierarchical-auto-regressive-search","children":[]},{"level":3,"title":"2.3 Dynamic GPU Memory Reuse","slug":"_2-3-dynamic-gpu-memory-reuse","link":"#_2-3-dynamic-gpu-memory-reuse","children":[]}]},{"level":2,"title":"3. Using LightSeq","slug":"_3-using-lightseq","link":"#_3-using-lightseq","children":[{"level":3,"title":"3.1 Installation","slug":"_3-1-installation","link":"#_3-1-installation","children":[]},{"level":3,"title":"3.2 Training examples using LightSeq","slug":"_3-2-training-examples-using-lightseq","link":"#_3-2-training-examples-using-lightseq","children":[]},{"level":3,"title":"3.3 Inference examples Using LightSeq","slug":"_3-3-inference-examples-using-lightseq","link":"#_3-3-inference-examples-using-lightseq","children":[]}]},{"level":2,"title":"4. Performance","slug":"_4-performance","link":"#_4-performance","children":[{"level":3,"title":"4.1 Training Performance","slug":"_4-1-training-performance","link":"#_4-1-training-performance","children":[]},{"level":3,"title":"4.2 Inference Performance","slug":"_4-2-inference-performance","link":"#_4-2-inference-performance","children":[]},{"level":3,"title":"4.3 More Inference Performance on Nvidia P4 and T4","slug":"_4-3-more-inference-performance-on-nvidia-p4-and-t4","link":"#_4-3-more-inference-performance-on-nvidia-p4-and-t4","children":[]},{"level":3,"title":"4.4 Real-world Cloud Computing Delay Test on GPT","slug":"_4-4-real-world-cloud-computing-delay-test-on-gpt","link":"#_4-4-real-world-cloud-computing-delay-test-on-gpt","children":[]}]},{"level":2,"title":"5. Reference","slug":"_5-reference","link":"#_5-reference","children":[]}],"git":{"createdTime":1663040715000,"updatedTime":1663040715000,"contributors":[{"name":"Lei Li","email":"lileicc@gmail.com","commits":1}]},"readingTime":{"minutes":4.14,"words":1241},"filePathRelative":"dl4mt/2021/lightseq/README.md","localizedDate":"December 10, 2021"}');export{e as data};
