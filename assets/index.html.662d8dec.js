const e=JSON.parse(`{"key":"v-0cc6ce02","path":"/mt/mnlp_blog/","title":"Multilingual Machine Translation with Large Language Models","lang":"en-US","frontmatter":{"title":"Multilingual Machine Translation with Large Language Models","author":"Hwijeen Ahn, William Chen","date":"2023-11-16T00:00:00.000Z","category":["MT"],"tag":["Multilingual MT"],"star":true,"summary":"Large Language Models (LLMs) like ChatGPT have rocked the world over the past year. They are able to perform almost any task you can think of, such as summarization, translation, and story-telling. But how do these LLMs work? And should you use them over existing tools? A recent study by AI researchers investigated how LLMs can be used for translation, and evaluate them against the best dedicated translation systems available. Our blog post today will summarize their findings and show how their study can be extended to new languages.\\n","head":[["meta",{"property":"og:url","content":"https://lileicc.github.io/blog/mt/mnlp_blog/"}],["meta",{"property":"og:site_name","content":"MLNLP Blog"}],["meta",{"property":"og:title","content":"Multilingual Machine Translation with Large Language Models"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:updated_time","content":"2023-11-18T00:45:15.000Z"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"article:author","content":"Hwijeen Ahn, William Chen"}],["meta",{"property":"article:tag","content":"Multilingual MT"}],["meta",{"property":"article:published_time","content":"2023-11-16T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-11-18T00:45:15.000Z"}]]},"excerpt":"<p>Large Language Models (LLMs) like <a href=\\"chat.openai.com\\">ChatGPT</a> have rocked the world over the past year. They are able to perform almost any task you can think of, such as summarization, translation, and story-telling. But how do these LLMs work? And should you use them over existing tools? A <a href=\\"https://arxiv.org/pdf/2304.04675.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">recent study<ExternalLinkIcon/></a> by AI researchers investigated how LLMs can be used for translation, and evaluate them against the best dedicated translation systems available. Our blog post today will summarize their findings and show how their study can be extended to new languages.</p>\\n","headers":[{"level":2,"title":"Introduction","slug":"introduction","link":"#introduction","children":[]},{"level":2,"title":"In-Context Learning","slug":"in-context-learning","link":"#in-context-learning","children":[]},{"level":2,"title":"LLMs vs Dedicated MT Models","slug":"llms-vs-dedicated-mt-models","link":"#llms-vs-dedicated-mt-models","children":[{"level":3,"title":"Evaluated Models","slug":"evaluated-models","link":"#evaluated-models","children":[]}]},{"level":2,"title":"Factors that Influence an LLM's Translation Performance","slug":"factors-that-influence-an-llm-s-translation-performance","link":"#factors-that-influence-an-llm-s-translation-performance","children":[]},{"level":2,"title":"How to use In-Context Learning on your own Data","slug":"how-to-use-in-context-learning-on-your-own-data","link":"#how-to-use-in-context-learning-on-your-own-data","children":[]},{"level":2,"title":"Conclusion","slug":"conclusion","link":"#conclusion","children":[]},{"level":2,"title":"References","slug":"references","link":"#references","children":[]}],"git":{"createdTime":1700172120000,"updatedTime":1700268315000,"contributors":[{"name":"wanchichen","email":"wchen6255@outlook.com","commits":6},{"name":"William Chen","email":"39677488+wanchichen@users.noreply.github.com","commits":1}]},"readingTime":{"minutes":3.59,"words":1078},"filePathRelative":"mt/mnlp_blog/README.md","localizedDate":"November 16, 2023"}`);export{e as data};
