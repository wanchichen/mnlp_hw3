const e=JSON.parse('{"key":"v-eef560ce","path":"/dl4mt/2021/mrasp2/","title":"Contrastive Learning for Many-to-many Multilingual Neural Machine Translation","lang":"en-US","frontmatter":{"title":"Contrastive Learning for Many-to-many Multilingual Neural Machine Translation","author":"Weixi Feng","date":"2021-11-20T00:00:00.000Z","tag":["Multilingual MT","Contrastive Learning","Zero-shot Translation","mRASP","Random Aligned Substitution"],"category":["MT","DL4MT"],"star":true,"summary":"How to develop a single unified model to translate from any language to any language?\\nThis work proposes a many-to-many translation system with emphasis on both English-centric and non-English directions. Many recent works have focused on proposing a single unified model for multiligual translation. These models are favorable because they are efficient and easy for deployment. However, most of these works focus on improving English-centric directions, which means that translation between two arbitrary languages may not be well supported. Therefore, in this paper, they propose a training method called mRASP2, including contrastive learning and alignment augmentation (AA) to train a unified multilingual translation system.  They also contribute a monolingual dataset called MC24. By making use of monolingual and bilingual language copora, the system is able to learn language-agnostic representation to support non-English directions better than before. Their system achieves great performances and outperforms a strong Transformer baseline by a large margin.\\n","head":[["meta",{"property":"og:url","content":"https://lileicc.github.io/blog/dl4mt/2021/mrasp2/"}],["meta",{"property":"og:site_name","content":"MLNLP Blog"}],["meta",{"property":"og:title","content":"Contrastive Learning for Many-to-many Multilingual Neural Machine Translation"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://lileicc.github.io/blog/"}],["meta",{"property":"og:updated_time","content":"2022-10-01T23:54:15.000Z"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"Contrastive Learning for Many-to-many Multilingual Neural Machine Translation"}],["meta",{"property":"article:author","content":"Weixi Feng"}],["meta",{"property":"article:tag","content":"Multilingual MT"}],["meta",{"property":"article:tag","content":"Contrastive Learning"}],["meta",{"property":"article:tag","content":"Zero-shot Translation"}],["meta",{"property":"article:tag","content":"mRASP"}],["meta",{"property":"article:tag","content":"Random Aligned Substitution"}],["meta",{"property":"article:published_time","content":"2021-11-20T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2022-10-01T23:54:15.000Z"}]]},"excerpt":"<p>How to develop a single unified model to translate from any language to any language?\\nThis work proposes a many-to-many translation system with emphasis on both English-centric and non-English directions. Many recent works have focused on proposing a single unified model for multiligual translation. These models are favorable because they are efficient and easy for deployment. However, most of these works focus on improving English-centric directions, which means that translation between two arbitrary languages may not be well supported. Therefore, in this paper, they propose a training method called mRASP2, including contrastive learning and alignment augmentation (AA) to train a unified multilingual translation system.  They also contribute a monolingual dataset called MC24. By making use of monolingual and bilingual language copora, the system is able to learn language-agnostic representation to support non-English directions better than before. Their system achieves great performances and outperforms a strong Transformer baseline by a large margin.</p>\\n","headers":[{"level":2,"title":"Baseline","slug":"baseline","link":"#baseline","children":[]},{"level":2,"title":"Multilingual Contrastive Learning","slug":"multilingual-contrastive-learning","link":"#multilingual-contrastive-learning","children":[]},{"level":2,"title":"Aligned Augmentation","slug":"aligned-augmentation","link":"#aligned-augmentation","children":[]},{"level":2,"title":"Datasets","slug":"datasets","link":"#datasets","children":[]},{"level":2,"title":"Supervised Direction","slug":"supervised-direction","link":"#supervised-direction","children":[]},{"level":2,"title":"Unsupervised Direction","slug":"unsupervised-direction","link":"#unsupervised-direction","children":[]},{"level":2,"title":"Zero-shot non-English Translation","slug":"zero-shot-non-english-translation","link":"#zero-shot-non-english-translation","children":[]},{"level":2,"title":"What is the importance of each contribution?","slug":"what-is-the-importance-of-each-contribution","link":"#what-is-the-importance-of-each-contribution","children":[]},{"level":2,"title":"How is the alignment of different languages in Visualization?","slug":"how-is-the-alignment-of-different-languages-in-visualization","link":"#how-is-the-alignment-of-different-languages-in-visualization","children":[]}],"git":{"createdTime":1663040715000,"updatedTime":1664668455000,"contributors":[{"name":"Lei Li","email":"lileicc@gmail.com","commits":2}]},"readingTime":{"minutes":5.24,"words":1572},"filePathRelative":"dl4mt/2021/mrasp2/README.md","localizedDate":"November 20, 2021"}');export{e as data};
